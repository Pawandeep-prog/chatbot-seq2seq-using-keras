{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport json \nimport tqdm\nimport re","metadata":{"_uuid":"3156596c-691c-4cde-b882-c979f4080329","_cell_guid":"d395a2fc-5cf6-411b-b4ed-a34616eab930","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:19.463484Z","iopub.execute_input":"2021-08-15T01:55:19.463856Z","iopub.status.idle":"2021-08-15T01:55:19.469602Z","shell.execute_reply.started":"2021-08-15T01:55:19.463818Z","shell.execute_reply":"2021-08-15T01:55:19.468730Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"_uuid":"93b8bdd4-cb8f-4697-af42-47f961e23e74","_cell_guid":"c87ff0c9-bc54-4d46-959f-a79a2573c060","trusted":true}},{"cell_type":"code","source":"\ndef clean_text(txt):\n    txt = txt.lower()    \n    txt.replace(\"\\'d\", \" had\")\n    txt.replace(\"\\'s\", \" is\")\n    txt.replace(\"\\'m\", \" am\")\n    txt.replace(\"don't\", \"do not\")\n    txt = re.sub(r'\\W+', ' ', txt)\n    \n    return txt\n\nwith open(\"../input/chatbot/data.json\", \"rb\") as f:\n\ttxt = json.load(f)\n\nchat_in = []\nchat_out = []\nmax_len = 30\n\nfor i in tqdm.tqdm(txt):\n    for index in range(len(i['dialog'])-1):\n        if (len(i['dialog'][index]['text']) < max_len) and (len(i['dialog'][index +1]['text']) < max_len):\n            chat_in.append(\"<sos> \" + clean_text(i['dialog'][index]['text']) + \" <eos>\")\n            chat_out.append(\"<sos> \" + clean_text(i['dialog'][index+1]['text'])+ \" <eos>\")\n\n\nvocabulary = {}\ncount = 1\nfor i in chat_in:\n    for j in i.split(' '):\n        if j not in vocabulary:\n            vocabulary[j] = count\n            count += 1\nfor i in chat_out:\n    for j in i.split(' '):\n        if j not in vocabulary:\n            vocabulary[j] = count\n            count += 1\n\n######## padding \nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\nchat_in_encoded = []\nchat_out_encoded = []\nfor i in chat_in:\n    seq = []\n    for j in i.split():\n        seq.append(vocabulary[j])\n    chat_in_encoded.append(pad_sequences([seq], maxlen=max_len+2, padding=\"post\").reshape(-1))\nchat_in_encoded = np.array(chat_in_encoded)\n\n\nfor i in chat_out:\n    seq = []\n    for j in i.split():\n        seq.append(vocabulary[j])\n    chat_out_encoded.append(pad_sequences([seq], maxlen=max_len+2, padding=\"post\").reshape(-1))\nchat_out_encoded = np.array(chat_out_encoded)\n\n\nvocabulary['<pad>'] = 0\n\nfinal_chat_out = []\nfor i in chat_out_encoded:\n    final_chat_out.append(i[1:])\nfinal_chat_out = np.array(final_chat_out)\nfinal_chat_out = pad_sequences(final_chat_out, max_len+2, padding=\"post\")\n\nfrom keras.utils import to_categorical\nfinal_chat_out = to_categorical(final_chat_out, num_classes=len(vocabulary))","metadata":{"_uuid":"43e84e18-5754-427f-8d99-06723270d177","_cell_guid":"2be8cf15-6d2b-4d1b-8a76-ebab2a5e9259","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:19.493514Z","iopub.execute_input":"2021-08-15T01:55:19.493793Z","iopub.status.idle":"2021-08-15T01:55:21.568857Z","shell.execute_reply.started":"2021-08-15T01:55:19.493765Z","shell.execute_reply":"2021-08-15T01:55:21.567985Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decoder_final_output, decoder_final_input, encoder_final, vocab, inv_vocab\n\nVOCAB_SIZE = len(vocabulary)\nMAX_LEN = max_len+2\nprint(VOCAB_SIZE)\n#print(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])","metadata":{"_uuid":"f066eb7e-2325-4f7d-a30d-98ef98e36b67","_cell_guid":"057ced76-8db9-4c9f-a9ec-50c88a2c4391","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:21.570601Z","iopub.execute_input":"2021-08-15T01:55:21.570974Z","iopub.status.idle":"2021-08-15T01:55:21.578369Z","shell.execute_reply.started":"2021-08-15T01:55:21.570944Z","shell.execute_reply":"2021-08-15T01:55:21.577297Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inv_vocab = {w:k for k,w in vocabulary.items()}","metadata":{"_uuid":"426f1c16-50fe-491b-bfc9-d24f0a3b5a0e","_cell_guid":"6af07c00-1159-40f1-895d-ddcbcac7a07a","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:21.579901Z","iopub.execute_input":"2021-08-15T01:55:21.580385Z","iopub.status.idle":"2021-08-15T01:55:21.588657Z","shell.execute_reply.started":"2021-08-15T01:55:21.580342Z","shell.execute_reply":"2021-08-15T01:55:21.587888Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final_chat_out.shape)","metadata":{"_uuid":"3b593d3d-5802-43fc-b9d5-b33881d3ac5d","_cell_guid":"f0aaeee8-dfc3-4927-a194-272b0d386180","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:21.614026Z","iopub.execute_input":"2021-08-15T01:55:21.614535Z","iopub.status.idle":"2021-08-15T01:55:21.619600Z","shell.execute_reply.started":"2021-08-15T01:55:21.614494Z","shell.execute_reply":"2021-08-15T01:55:21.618740Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Glove Embedding","metadata":{"_uuid":"bac1c7f3-ea70-4ed0-8553-95602b4cbc19","_cell_guid":"a5c42da4-e468-4fdf-b085-8933dbe3fad5","trusted":true}},{"cell_type":"code","source":"\nembeddings_index = {}\nwith open('../input/glove6b50d/glove.6B.50d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n    f.close()\n\nprint(\"Glove Loded!\")","metadata":{"_uuid":"01447b67-83b3-4953-b827-1debe6595359","_cell_guid":"7b93dcd1-4847-41d0-a940-9a96e5dd313f","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:21.621029Z","iopub.execute_input":"2021-08-15T01:55:21.621637Z","iopub.status.idle":"2021-08-15T01:55:31.226376Z","shell.execute_reply.started":"2021-08-15T01:55:21.621598Z","shell.execute_reply":"2021-08-15T01:55:31.225407Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = vocabulary","metadata":{"_uuid":"30116534-779b-4b25-a041-35ab5a72c1a0","_cell_guid":"df35cb92-abe0-4966-a1da-d389a7f04495","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.227675Z","iopub.execute_input":"2021-08-15T01:55:31.228219Z","iopub.status.idle":"2021-08-15T01:55:31.232706Z","shell.execute_reply.started":"2021-08-15T01:55:31.228177Z","shell.execute_reply":"2021-08-15T01:55:31.231566Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nembedding_dimention = 50\ndef embedding_matrix_creater(embedding_dimention, word_index):\n    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n          # words not found in embedding index will be all-zeros.\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix\nembedding_matrix = embedding_matrix_creater(50, word_index=vocab)","metadata":{"_uuid":"495c511d-aaeb-4eaf-8b8b-d97d0996fdf1","_cell_guid":"71fc8a74-7de5-435a-8a9b-1b71ad867da4","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.234529Z","iopub.execute_input":"2021-08-15T01:55:31.234990Z","iopub.status.idle":"2021-08-15T01:55:31.249169Z","shell.execute_reply.started":"2021-08-15T01:55:31.234950Z","shell.execute_reply":"2021-08-15T01:55:31.248056Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(embeddings_index)","metadata":{"_uuid":"ad4978f8-f579-48bb-952f-6d378ae28195","_cell_guid":"332fdbdc-71ab-42ef-b9b7-98ce808562ed","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.250413Z","iopub.execute_input":"2021-08-15T01:55:31.250790Z","iopub.status.idle":"2021-08-15T01:55:31.344415Z","shell.execute_reply.started":"2021-08-15T01:55:31.250753Z","shell.execute_reply":"2021-08-15T01:55:31.343177Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{"_uuid":"c01c93ce-365b-46e2-a25c-a481f1b9cf30","_cell_guid":"48329305-3c79-4815-89bb-1b73f8f894c8","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.369825Z","iopub.execute_input":"2021-08-15T01:55:31.370439Z","iopub.status.idle":"2021-08-15T01:55:31.377019Z","shell.execute_reply.started":"2021-08-15T01:55:31.370395Z","shell.execute_reply":"2021-08-15T01:55:31.375622Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix[0]","metadata":{"_uuid":"45e35c58-f5b7-4d27-a027-c0e144b348a0","_cell_guid":"e5eff9a1-b5ab-4905-93f9-40e89c30c5cf","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.378626Z","iopub.execute_input":"2021-08-15T01:55:31.379428Z","iopub.status.idle":"2021-08-15T01:55:31.389322Z","shell.execute_reply.started":"2021-08-15T01:55:31.379386Z","shell.execute_reply":"2021-08-15T01:55:31.388028Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"_uuid":"e294d449-8c47-42c8-950e-17f4e84b2e57","_cell_guid":"689a5a54-139f-4a14-83b2-12f6ee3a1084","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout","metadata":{"_uuid":"962dc056-5466-40ee-8921-fc9dd6656c4b","_cell_guid":"15faf5dd-8e4b-44aa-aa24-c92c8e58de35","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.391242Z","iopub.execute_input":"2021-08-15T01:55:31.392028Z","iopub.status.idle":"2021-08-15T01:55:31.401530Z","shell.execute_reply.started":"2021-08-15T01:55:31.391988Z","shell.execute_reply":"2021-08-15T01:55:31.400381Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed = Embedding(VOCAB_SIZE+1, \n                  50,\n                  input_length=MAX_LEN,\n                  trainable=True)\n\nembed.build((None,))\nembed.set_weights([embedding_matrix])","metadata":{"_uuid":"13b4d2e0-31a7-46a6-b021-e66c222b30fb","_cell_guid":"67b9b010-c545-4656-91bb-d4f2326b5385","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:31.404255Z","iopub.execute_input":"2021-08-15T01:55:31.404859Z","iopub.status.idle":"2021-08-15T01:55:33.405400Z","shell.execute_reply.started":"2021-08-15T01:55:31.404822Z","shell.execute_reply":"2021-08-15T01:55:33.404611Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_inp = Input(shape=(MAX_LEN,))\ndec_inp = Input(shape=(MAX_LEN,))","metadata":{"_uuid":"36323d1c-cd2e-48a5-855e-2328e1d66a57","_cell_guid":"fed48bfc-d4f4-4344-9dcf-cc287d58afa0","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:33.407625Z","iopub.execute_input":"2021-08-15T01:55:33.407910Z","iopub.status.idle":"2021-08-15T01:55:33.417859Z","shell.execute_reply.started":"2021-08-15T01:55:33.407883Z","shell.execute_reply":"2021-08-15T01:55:33.416941Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_embed = embed(enc_inp)\n\nenc_lstm = Bidirectional(LSTM(200, return_sequences=True, return_state=True))\nenc_op, f_h, f_c, b_h, b_c = enc_lstm(enc_embed)\n\nh = Concatenate()([f_h, b_h])\nc = Concatenate()([f_c, b_c])\nenc_states = [h, c]\n\ndec_embed = embed(dec_inp)\ndec_lstm = LSTM(400, return_sequences=True, return_state=True)\ndec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n\ndense = Dense(VOCAB_SIZE, activation='softmax')\n\ndense_op = dense(dec_op)\n\nmodel = Model([enc_inp, dec_inp], dense_op)\n\nmodel.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')","metadata":{"_uuid":"ac7a4497-114f-4271-9c55-32647764c271","_cell_guid":"eee0d370-7f86-444c-a7d5-18ce260cd65f","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:33.419638Z","iopub.execute_input":"2021-08-15T01:55:33.420009Z","iopub.status.idle":"2021-08-15T01:55:34.466354Z","shell.execute_reply.started":"2021-08-15T01:55:33.419972Z","shell.execute_reply":"2021-08-15T01:55:34.465597Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding CallBack","metadata":{"_uuid":"f57eeca2-b107-4295-9831-2863823a336b","_cell_guid":"4b39b2ba-66aa-42d7-8cd3-72f409ccfa35","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback","metadata":{"_uuid":"ba28d7f2-22be-479f-9069-d8cac1841a95","_cell_guid":"d8cab9b6-8dd4-46bd-af76-1cddf7bd63e3","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:34.467580Z","iopub.execute_input":"2021-08-15T01:55:34.467951Z","iopub.status.idle":"2021-08-15T01:55:34.475155Z","shell.execute_reply.started":"2021-08-15T01:55:34.467913Z","shell.execute_reply":"2021-08-15T01:55:34.474245Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PrintCallBack(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % 10 == 0:\n            enc_model = Model([enc_inp], enc_states)\n\n            # decoder Model\n            decoder_state_input_h = Input(shape=(400,))\n            decoder_state_input_c = Input(shape=(400,))\n\n            decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n\n            decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n                                                initial_state=decoder_states_inputs)\n\n\n            decoder_states = [state_h, state_c]\n\n\n            dec_model = Model([dec_inp, decoder_states_inputs],\n                                                  [decoder_outputs, decoder_states])\n            \n\n            ins = [\"hello\", \"how are you\", \"what is your name\", \"i want to marry you\", \"i will kill you\", \"i hate you\", \"what do you do\"]\n            \n            for i in ins:\n                print()\n                print(i)\n                \n                prepro1 = i\n                prepro1 = clean_text(prepro1)\n                ## prepro1 = \"hello\"\n                prepro1 = \"<sos> \" + prepro1 + \" <eos>\"\n\n                prepro = [prepro1]\n                ## prepro1 = [\"hello\"]\n\n                txt = []\n                for x in prepro:\n                    # x = \"hello\"\n                    lst = []\n                    for y in x.split():\n                        ## y = \"hello\"\n                        try:\n                            lst.append(vocabulary[y])\n                            ## vocab['hello'] = 454\n                        except:\n                            lst.append(vocabulary['<OUT>'])\n                    txt.append(lst)\n\n                ## txt = [[454]]\n                txt = pad_sequences(txt, max_len+2, padding='post')\n\n                ## txt = [[454,0,0,0,.........13]]\n\n                stat = enc_model.predict( txt )\n\n                empty_target_seq = np.zeros( ( 1 , 1) )\n                 ##   empty_target_seq = [0]\n\n\n                empty_target_seq[0, 0] = vocabulary['<sos>']\n                ##    empty_target_seq = [255]\n\n                stop_condition = False\n                decoded_translation = ''\n\n                while not stop_condition :\n\n                    dec_outputs , dec_states_op= dec_model.predict([ empty_target_seq, stat] )\n                    decoder_concat_input = dense(dec_outputs)\n                    ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n\n                    sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n                    ## sampled_word_index = [2]\n\n                    sampled_word = inv_vocab[sampled_word_index] + ' '\n\n                    ## inv_vocab[2] = 'hi'\n                    ## sampled_word = 'hi '\n\n                    if sampled_word != '<eos> ':\n                        decoded_translation += sampled_word  \n\n                    if sampled_word == '<eos> ' or len(decoded_translation.split()) > max_len:\n                        stop_condition = True \n\n                    empty_target_seq = np.zeros( ( 1 , 1 ) )  \n                    empty_target_seq[ 0 , 0 ] = sampled_word_index\n                    ## <SOS> - > hi\n                    ## hi --> <EOS>\n                    stat = dec_states_op.copy()\n\n                print(\"chatbot attention : \", decoded_translation )\n                print(\"==============================================\")","metadata":{"_uuid":"b9cfe831-fc16-4e21-944c-15d806dfe6f1","_cell_guid":"842792a7-77bf-4622-b173-1b7116df4c43","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:34.476589Z","iopub.execute_input":"2021-08-15T01:55:34.477176Z","iopub.status.idle":"2021-08-15T01:55:34.496824Z","shell.execute_reply.started":"2021-08-15T01:55:34.477135Z","shell.execute_reply":"2021-08-15T01:55:34.495889Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting the model","metadata":{"_uuid":"d72965b1-fe31-477e-8b3b-25a1c6a99c07","_cell_guid":"a4d35fb6-7c3b-4e56-b0a7-add32e9ff2e5","trusted":true}},{"cell_type":"code","source":"\n\nmodel.fit([chat_in_encoded, chat_out_encoded], final_chat_out, epochs = 400, batch_size=24, callbacks=[PrintCallBack()])\n\n\n#######################################################################","metadata":{"_uuid":"1273d449-00b3-4ce5-b486-8f09b72dcd9c","_cell_guid":"64766ee5-673f-47e1-b828-1fefef3f5516","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T01:55:34.498174Z","iopub.execute_input":"2021-08-15T01:55:34.498582Z","iopub.status.idle":"2021-08-15T02:11:48.631829Z","shell.execute_reply.started":"2021-08-15T01:55:34.498542Z","shell.execute_reply":"2021-08-15T02:11:48.629259Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Setup","metadata":{"_uuid":"82f1d953-147e-4927-8bc7-db29579f44fc","_cell_guid":"0b1cd11a-e3c1-4d12-a7ea-a24a8ca9d0d1","trusted":true}},{"cell_type":"code","source":"enc_model = Model([enc_inp], enc_states)\n\n\n\n# decoder Model\ndecoder_state_input_h = Input(shape=(400,))\ndecoder_state_input_c = Input(shape=(400,))\n\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n\ndecoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n                                    initial_state=decoder_states_inputs)\n\n\ndecoder_states = [state_h, state_c]\n\n\ndec_model = Model([dec_inp, decoder_states_inputs],\n                                      [decoder_outputs, decoder_states])","metadata":{"_uuid":"480dac76-4863-4341-b8cf-91e9df6a5845","_cell_guid":"2188a77f-ef2e-4d45-9ece-24fb72abd28c","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T02:11:55.595574Z","iopub.execute_input":"2021-08-15T02:11:55.595936Z","iopub.status.idle":"2021-08-15T02:11:55.798344Z","shell.execute_reply.started":"2021-08-15T02:11:55.595900Z","shell.execute_reply":"2021-08-15T02:11:55.797610Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Part","metadata":{"_uuid":"e3e5e9cd-54d5-4d57-8e7f-b58788cfa08b","_cell_guid":"8b140bba-d2aa-4c3a-ab10-05b3f34f77f3","trusted":true}},{"cell_type":"code","source":"\nprepro1 = \"\"\nwhile prepro1 != 'q':\n    prepro1  = input(\"you : \")\n    ## prepro1 = \"Hello\"\n    \n    \n    prepro1 = clean_text(prepro1)\n    ## prepro1 = \"hello\"\n    prepro1 = \"<sos> \" + prepro1 + \" <eos>\"\n\n    prepro = [prepro1]\n    ## prepro1 = [\"hello\"]\n\n    txt = []\n    for x in prepro:\n        # x = \"hello\"\n        lst = []\n        for y in x.split():\n            ## y = \"hello\"\n            try:\n                lst.append(vocabulary[y])\n                ## vocab['hello'] = 454\n            except:\n                lst.append(vocabulary['<OUT>'])\n        txt.append(lst)\n\n    ## txt = [[454]]\n    txt = pad_sequences(txt, max_len+2, padding='post')\n\n    ## txt = [[454,0,0,0,.........13]]\n\n    stat = enc_model.predict( txt )\n\n    empty_target_seq = np.zeros( ( 1 , 1) )\n     ##   empty_target_seq = [0]\n\n\n    empty_target_seq[0, 0] = vocabulary['<sos>']\n    ##    empty_target_seq = [255]\n\n    stop_condition = False\n    decoded_translation = ''\n\n    while not stop_condition :\n\n        dec_outputs , dec_states_op= dec_model.predict([ empty_target_seq, stat] )\n        decoder_concat_input = dense(dec_outputs)\n        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n\n        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n        ## sampled_word_index = [2]\n\n        sampled_word = inv_vocab[sampled_word_index] + ' '\n\n        ## inv_vocab[2] = 'hi'\n        ## sampled_word = 'hi '\n\n        if sampled_word != '<eos> ':\n            decoded_translation += sampled_word  \n\n        if sampled_word == '<eos> ' or len(decoded_translation.split()) > max_len:\n            stop_condition = True \n\n        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n        empty_target_seq[ 0 , 0 ] = sampled_word_index\n        ## <SOS> - > hi\n        ## hi --> <EOS>\n        stat = dec_states_op.copy()\n\n    print(\"chatbot : \", decoded_translation )\n    print(\"==============================================\")","metadata":{"_uuid":"f2d59aa0-726c-49f6-80e7-5f9060d9317d","_cell_guid":"5e9347ef-8590-4009-b44f-8e01adde456b","collapsed":false,"execution":{"iopub.status.busy":"2021-08-15T02:23:19.000930Z","iopub.execute_input":"2021-08-15T02:23:19.001257Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"feaa37e6-c6ec-402e-8516-74231b4c2ef8","_cell_guid":"dd24a687-ee12-4929-9ce9-49f3e9a4700f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"c80d2e1d-a93b-4f66-a75c-f5e6b71783a3","_cell_guid":"d9ecc0b7-2250-4350-8a33-8f85281b7577","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"b42b4d02-d8aa-4a65-bd19-7a4da0c3cd93","_cell_guid":"8de2acb1-bf00-4c3a-9790-3c7ef3e7ea3d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}